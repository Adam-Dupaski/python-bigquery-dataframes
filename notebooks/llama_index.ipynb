{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0579a5cf36a841cbaa8b1f3f6c8c279a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57198a22031b4a9eaf59808fad0f1d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ead7e844c344c1f9cb564c95dea6a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4fb245733d4cfca33c9b11b98a7788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f5649ba8ce469aad48e034b2acc3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d224adb867449b7a326f13d04a464d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ffff535a1f43e383de6c470205a394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c899c7a4b564ae0953161d498c5dfc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b858ccc1fa0943cf9dc4a256df2cbfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412b452575d446c8b35e8a51cbb854d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d30d71909648ce98950968ff5486ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "# bge embedding model\n",
    "Settings.embed_model = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# ollama\n",
    "Settings.llm = Ollama(model=\"mistral\", request_timeout=30.0)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model=\"mistral\", request_timeout=300.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The author grew up working on writing and programming before college. He started writing stories as a beginning writer but found them to be lacking in plot. His early attempts at programming were on an IBM 1401 computer, where he struggled to understand its capabilities and wrote simple programs without much functionality. He was fascinated by microcomputers and eventually convinced his father to buy him one, which allowed him to write more complex programs and explore the potential of computing. Despite his interest in programming, he planned to study philosophy in college but became disillusioned with the field and switched to AI instead. His experiences growing up laid the foundation for his future interests and pursuits.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"data/dremel.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_splitter = SentenceSplitter(chunk_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = base_splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 85ccd0d1-8f52-4905-9394-be610058a3c7\n",
      "Text: Dremel: Interactive Analysis of Web-Scale Datasets Sergey\n",
      "Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva\n",
      "Shivakumar, Matt Tolton, Theo Vassilakis Google, Inc.\n",
      "{melnik,andrey,jlong,gromer,shiva,mtolton,theov }@google.com ABSTRACT\n",
      "Dremel is a scalable, interactive ad-hoc query system for analy- sis\n",
      "of read-only nested data. By combi...\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: deffb4c0-b73f-4ba0-b442-ecd4df3bdad7\n",
      "Text: Performing interactive data analysis at scale demands a high de-\n",
      "gree of parallelism. For example, reading one terabyte of com- pressed\n",
      "data in one second using today’s commodity disks would require tens of\n",
      "thousands of disks. Similarly, CPU-intensive queries may need to run\n",
      "on thousands of cores to complete within seconds. At Google, massively\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(nodes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.schema.TextNode"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nodes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': 'deffb4c0-b73f-4ba0-b442-ecd4df3bdad7',\n",
       " 'embedding': None,\n",
       " 'metadata': {'page_label': '1',\n",
       "  'file_name': 'dremel.pdf',\n",
       "  'file_path': 'data/dremel.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 1251598,\n",
       "  'creation_date': '2024-04-16',\n",
       "  'last_modified_date': '2024-04-16'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'relationships': {<NodeRelationship.SOURCE: '1'>: {'node_id': '8cbf4742-4799-4a0d-810b-78d5f59a8b95',\n",
       "   'node_type': <ObjectType.DOCUMENT: '4'>,\n",
       "   'metadata': {'page_label': '1',\n",
       "    'file_name': 'dremel.pdf',\n",
       "    'file_path': 'data/dremel.pdf',\n",
       "    'file_type': 'application/pdf',\n",
       "    'file_size': 1251598,\n",
       "    'creation_date': '2024-04-16',\n",
       "    'last_modified_date': '2024-04-16'},\n",
       "   'hash': '599b0f5a032c3c94413430eba6f185cfa7a8a74139179ef491ebe29eaeff494e',\n",
       "   'class_name': 'RelatedNodeInfo'},\n",
       "  <NodeRelationship.PREVIOUS: '2'>: {'node_id': '85ccd0d1-8f52-4905-9394-be610058a3c7',\n",
       "   'node_type': <ObjectType.TEXT: '1'>,\n",
       "   'metadata': {'page_label': '1',\n",
       "    'file_name': 'dremel.pdf',\n",
       "    'file_path': 'data/dremel.pdf',\n",
       "    'file_type': 'application/pdf',\n",
       "    'file_size': 1251598,\n",
       "    'creation_date': '2024-04-16',\n",
       "    'last_modified_date': '2024-04-16'},\n",
       "   'hash': '66c845bb2809b66c7ffd081336035704004d0d34aae5739830b1f558eed2e41b',\n",
       "   'class_name': 'RelatedNodeInfo'},\n",
       "  <NodeRelationship.NEXT: '3'>: {'node_id': '16496cef-5828-480e-9ed6-3194c0cc00d6',\n",
       "   'node_type': <ObjectType.TEXT: '1'>,\n",
       "   'metadata': {},\n",
       "   'hash': '092158002d8b9bac15454466472561e7d53b4ccedc223e931d685e8be5c22d15',\n",
       "   'class_name': 'RelatedNodeInfo'}},\n",
       " 'text': 'Performing interactive data analysis at scale demands a high de-\\ngree of parallelism. For example, reading one terabyte of com-\\npressed data in one second using today’s commodity disks would\\nrequire tens of thousands of disks. Similarly, CPU-intensive\\nqueries may need to run on thousands of cores to complete within\\nseconds. At Google, massively parallel computing is done using\\nshared clusters of commodity machines [5]. A cluster typically\\nhosts a multitude of distributed applications that share resources,\\nhave widely varying workloads, and run on machines with different\\nhardware parameters. An individual worker in a distributed appli-\\ncation may take much longer to execute a given task than others,\\nor may never complete due to failures or preemption by the cluster\\nmanagement system. Hence, dealing with stragglers and failures is\\nessential for achieving fast execution and fault tolerance [10].\\nThe data used in web and scientiﬁc computing is often non-\\nrelational. Hence, a ﬂexible data model is essential in these do-\\nmains. Data structures used in programming languages, messages\\nPermission to make digital or hard copies of all or part of this work for\\npersonal or classroom use is granted without fee provided that copies are\\nnot made or distributed for proﬁt or commercial advantage and that copies\\nbear this notice and the full citation on the ﬁrst page. To copy otherwise, to\\nrepublish, to post on servers or to redistribute to lists, requires prior speciﬁc\\npermission and/or a fee. Articles from this volume were presented at The\\n36th International Conference on Very Large Data Bases, September 13-17,\\n2010, Singapore.\\nProceedings of the VLDB Endowment, V ol. 3, No. 1\\nCopyright 2010 VLDB Endowment 2150-8097/10/09... $10.00.exchanged by distributed systems, structured documents, etc. lend\\nthemselves naturally to a nested representation. Normalizing and\\nrecombining such data at web scale is usually prohibitive. A nested\\ndata model underlies most of structured data processing at Google\\n[21] and reportedly at other major web companies.',\n",
       " 'start_char_idx': 1364,\n",
       " 'end_char_idx': 3424,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}',\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_seperator': '\\n',\n",
       " 'class_name': 'TextNode'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Performing interactive data analysis at scale demands a high de-\\ngree of parallelism. For example, reading one terabyte of com-\\npressed data in one second using today’s commodity disks would\\nrequire tens of thousands of disks. Similarly, CPU-intensive\\nqueries may need to run on thousands of cores to complete within\\nseconds. At Google, massively parallel computing is done using\\nshared clusters of commodity machines [5]. A cluster typically\\nhosts a multitude of distributed applications that share resources,\\nhave widely varying workloads, and run on machines with different\\nhardware parameters. An individual worker in a distributed appli-\\ncation may take much longer to execute a given task than others,\\nor may never complete due to failures or preemption by the cluster\\nmanagement system. Hence, dealing with stragglers and failures is\\nessential for achieving fast execution and fault tolerance [10].\\nThe data used in web and scientiﬁc computing is often non-\\nrelational. Hence, a ﬂexible data model is essential in these do-\\nmains. Data structures used in programming languages, messages\\nPermission to make digital or hard copies of all or part of this work for\\npersonal or classroom use is granted without fee provided that copies are\\nnot made or distributed for proﬁt or commercial advantage and that copies\\nbear this notice and the full citation on the ﬁrst page. To copy otherwise, to\\nrepublish, to post on servers or to redistribute to lists, requires prior speciﬁc\\npermission and/or a fee. Articles from this volume were presented at The\\n36th International Conference on Very Large Data Bases, September 13-17,\\n2010, Singapore.\\nProceedings of the VLDB Endowment, V ol. 3, No. 1\\nCopyright 2010 VLDB Endowment 2150-8097/10/09... $10.00.exchanged by distributed systems, structured documents, etc. lend\\nthemselves naturally to a nested representation. Normalizing and\\nrecombining such data at web scale is usually prohibitive. A nested\\ndata model underlies most of structured data processing at Google\\n[21] and reportedly at other major web companies.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

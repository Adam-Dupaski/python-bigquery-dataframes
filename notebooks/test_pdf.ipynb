{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20231228'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfminer.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "text = extract_text(\"data/dremel.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dremel: Interactive Analysis of Web-Scale Datasets\n",
      "\n",
      "Sergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer,\n",
      "Shiva Shivakumar, Matt Tolton, Theo Vassilakis\n",
      "Google, Inc.\n",
      "{melnik,andrey,jlong,gromer,shiva,mtolton,theov}@google.com\n",
      "\n",
      "ABSTRACT\n",
      "Dremel is a scalable, interactive ad-hoc query system for analy-\n",
      "sis of read-only nested data. By combining multi-level execution\n",
      "trees and columnar data layout, it is capable of running aggrega-\n",
      "tion queries over trillion-row tables in seconds. The system scales\n",
      "to thousands of CPUs and petabytes of data, and has thousands\n",
      "In this paper, we describe the architecture\n",
      "of users at Google.\n",
      "and implementation of Dremel, and explain how it complements\n",
      "MapReduce-based computing. We present a novel columnar stor-\n",
      "age representation for nested records and discuss experiments on\n",
      "few-thousand node instances of the system.\n",
      "\n",
      "INTRODUCTION\n",
      "\n",
      "1.\n",
      "Large-scale analytical data processing has become widespread in\n",
      "web companies and across industries, not least due to low-cost\n",
      "storage that enabled collecting vast amounts of business-critical\n",
      "data. Putting this data at the ﬁngertips of analysts and engineers\n",
      "has grown increasingly important; interactive response times of-\n",
      "ten make a qualitative difference in data exploration, monitor-\n",
      "ing, online customer support, rapid prototyping, debugging of data\n",
      "pipelines, and other tasks.\n",
      "\n",
      "Performing interactive data analysis at scale demands a high de-\n",
      "gree of parallelism. For example, reading one terabyte of com-\n",
      "pressed data in one second using today’s commodity disks would\n",
      "require tens of thousands of disks.\n",
      "Similarly, CPU-intensive\n",
      "queries may need to run on thousands of cores to complete within\n",
      "seconds. At Google, massively parallel computing is done using\n",
      "shared clusters of commodity machines [5]. A cluster typically\n",
      "hosts a multitude of distributed applications that share resources,\n",
      "have widely varying workloads, and run on machines with different\n",
      "hardware parameters. An individual worker in a distributed appli-\n",
      "cation may take much longer to execute a given task than others,\n",
      "or may never complete due to failures or preemption by the cluster\n",
      "management system. Hence, dealing with stragglers and failures is\n",
      "essential for achieving fast execution and fault tolerance [10].\n",
      "\n",
      "The data used in web and scientiﬁc computing is often non-\n",
      "relational. Hence, a ﬂexible data model is essential in these do-\n",
      "mains. Data structures used in programming languages, messages\n",
      "\n",
      "Permission to make digital or hard copies of all or part of this work for\n",
      "personal or classroom use is granted without fee provided that copies are\n",
      "not made or distributed for proﬁt or commercial advantage and that copies\n",
      "bear this notice and the full citation on the ﬁrst page. To copy otherwise, to\n",
      "republish, to post on servers or to redistribute to lists, requires prior speciﬁc\n",
      "permission and/or a fee. Articles from this volume were presented at The\n",
      "36th International Conference on Very Large Data Bases, September 13-17,\n",
      "2010, Singapore.\n",
      "Proceedings of the VLDB Endowment, Vol. 3, No. 1\n",
      "Copyright 2010 VLDB Endowment 2150-8097/10/09... $ 10.00.\n",
      "\n",
      "exchanged by distributed systems, structured documents, etc. lend\n",
      "themselves naturally to a nested representation. Normalizing and\n",
      "recombining such data at web scale is usually prohibitive. A nested\n",
      "data model underlies most of structured data processing at Google\n",
      "[21] and reportedly at other major web companies.\n",
      "\n",
      "This paper describes a system called Dremel1 that supports inter-\n",
      "active analysis of very large datasets over shared clusters of com-\n",
      "modity machines. Unlike traditional databases, it is capable of op-\n",
      "erating on in situ nested data. In situ refers to the ability to access\n",
      "data ‘in place’, e.g., in a distributed ﬁle system (like GFS [14]) or\n",
      "another storage layer (e.g., Bigtable [8]). Dremel can execute many\n",
      "queries over such data that would ordinarily require a sequence of\n",
      "MapReduce (MR [12]) jobs, but at a fraction of the execution time.\n",
      "Dremel is not intended as a replacement for MR and is often used\n",
      "in conjunction with it to analyze outputs of MR pipelines or rapidly\n",
      "prototype larger computations.\n",
      "\n",
      "Dremel has been in production since 2006 and has thousands of\n",
      "users within Google. Multiple instances of Dremel are deployed in\n",
      "the company, ranging from tens to thousands of nodes. Examples\n",
      "of using the system include:\n",
      "\n",
      "• Analysis of crawled web documents.\n",
      "• Tracking install data for applications on Android Market.\n",
      "• Crash reporting for Google products.\n",
      "• OCR results from Google Books.\n",
      "• Spam analysis.\n",
      "• Debugging of map tiles on Google Maps.\n",
      "• Tablet migrations in managed Bigtable instances.\n",
      "• Results of tests run on Google’s distributed build system.\n",
      "• Disk I/O statistics for hundreds of thousands of disks.\n",
      "• Resource monitoring for jobs run in Google’s data centers.\n",
      "• Symbols and dependencies in Google’s codebase.\n",
      "\n",
      "Dremel builds on ideas from web search and parallel DBMSs.\n",
      "First, its architecture borrows the concept of a serving tree used in\n",
      "distributed search engines [11]. Just like a web search request, a\n",
      "query gets pushed down the tree and is rewritten at each step. The\n",
      "result of the query is assembled by aggregating the replies received\n",
      "from lower levels of the tree. Second, Dremel provides a high-level,\n",
      "SQL-like language to express ad hoc queries. In contrast to layers\n",
      "such as Pig [18] and Hive [16], it executes queries natively without\n",
      "translating them into MR jobs.\n",
      "\n",
      "Lastly, and importantly, Dremel uses a column-striped storage\n",
      "representation, which enables it to read less data from secondary\n",
      "\n",
      "1Dremel is a brand of power tools that primarily rely on their speed\n",
      "as opposed to torque. We use this name for an internal project only.\n",
      "\n",
      "\fstorage and reduce CPU cost due to cheaper compression. Column\n",
      "stores have been adopted for analyzing relational data [1] but to the\n",
      "best of our knowledge have not been extended to nested data mod-\n",
      "els. The columnar storage format that we present is supported by\n",
      "many data processing tools at Google, including MR, Sawzall [20],\n",
      "and FlumeJava [7].\n",
      "\n",
      "In this paper we make the following contributions:\n",
      "\n",
      "• We describe a novel columnar storage format for nested\n",
      "data. We present algorithms for dissecting nested records\n",
      "into columns and reassembling them (Section 4).\n",
      "\n",
      "• We outline Dremel’s query language and execution. Both are\n",
      "designed to operate efﬁciently on column-striped nested data\n",
      "and do not require restructuring of nested records (Section 5).\n",
      "• We show how execution trees used in web search systems can\n",
      "be applied to database processing, and explain their beneﬁts\n",
      "for answering aggregation queries efﬁciently (Section 6).\n",
      "• We present experiments on trillion-record, multi-terabyte\n",
      "datasets, conducted on system instances running on 1000-\n",
      "4000 nodes (Section 7).\n",
      "\n",
      "This paper is structured as follows. In Section 2, we explain how\n",
      "Dremel is used for data analysis in combination with other data\n",
      "management tools. Its data model is presented in Section 3. The\n",
      "main contributions listed above are covered in Sections 4-8. Re-\n",
      "lated work is discussed in Section 9. Section 10 is the conclusion.\n",
      "\n",
      "2. BACKGROUND\n",
      "We start by walking through a scenario that illustrates how interac-\n",
      "tive query processing ﬁts into a broader data management ecosys-\n",
      "tem. Suppose that Alice, an engineer at Google, comes up with a\n",
      "novel idea for extracting new kinds of signals from web pages. She\n",
      "runs an MR job that cranks through the input data and produces a\n",
      "dataset containing the new signals, stored in billions of records in\n",
      "the distributed ﬁle system. To analyze the results of her experiment,\n",
      "she launches Dremel and executes several interactive commands:\n",
      "\n",
      "DEFINE TABLE t AS /path/to/data/*\n",
      "SELECT TOP(signal1, 100), COUNT(*) FROM t\n",
      "\n",
      "Her commands execute in seconds. She runs a few other queries\n",
      "to convince herself that her algorithm works. She ﬁnds an irregular-\n",
      "ity in signal1 and digs deeper by writing a FlumeJava [7] program\n",
      "that performs a more complex analytical computation over her out-\n",
      "put dataset. Once the issue is ﬁxed, she sets up a pipeline which\n",
      "processes the incoming input data continuously. She formulates a\n",
      "few canned SQL queries that aggregate the results of her pipeline\n",
      "across various dimensions, and adds them to an interactive dash-\n",
      "board. Finally, she registers her new dataset in a catalog so other\n",
      "engineers can locate and query it quickly.\n",
      "\n",
      "The above scenario requires interoperation between the query\n",
      "processor and other data management tools. The ﬁrst ingredient for\n",
      "that is a common storage layer. The Google File System (GFS [14])\n",
      "is one such distributed storage layer widely used in the company.\n",
      "GFS uses replication to preserve the data despite faulty hardware\n",
      "and achieve fast response times in presence of stragglers. A high-\n",
      "performance storage layer is critical for in situ data management. It\n",
      "allows accessing the data without a time-consuming loading phase,\n",
      "which is a major impedance to database usage in analytical data\n",
      "processing [13], where it is often possible to run dozens of MR\n",
      "analyses before a DBMS is able to load the data and execute a sin-\n",
      "gle query. As an added beneﬁt, data in a ﬁle system can be con-\n",
      "veniently manipulated using standard tools, e.g., to transfer to an-\n",
      "other cluster, change access privileges, or identify a subset of data\n",
      "for analysis based on ﬁle names.\n",
      "\n",
      "Figure 1: Record-wise vs. columnar representation of nested data\n",
      "\n",
      "The second ingredient for building interoperable data manage-\n",
      "ment components is a shared storage format. Columnar storage\n",
      "proved successful for ﬂat relational data but making it work for\n",
      "Google required adapting it to a nested data model. Figure 1 illus-\n",
      "trates the main idea: all values of a nested ﬁeld such as A.B.C are\n",
      "stored contiguously. Hence, A.B.C can be retrieved without read-\n",
      "ing A.E, A.B.D, etc. The challenge that we address is how to pre-\n",
      "serve all structural information and be able to reconstruct records\n",
      "from an arbitrary subset of ﬁelds. Next we discuss our data model,\n",
      "and then turn to algorithms and query processing.\n",
      "\n",
      "3. DATA MODEL\n",
      "In this section we present Dremel’s data model and introduce some\n",
      "terminology used later. The data model originated in the context\n",
      "of distributed systems (which explains its name, ‘Protocol Buffers’\n",
      "[21]), is used widely at Google, and is available as an open source\n",
      "implementation. The data model is based on strongly-typed nested\n",
      "records. Its abstract syntax is given by:\n",
      "\n",
      "τ = dom | (cid:104)A1 : τ [∗|?], . . . , An : τ [∗|?](cid:105)\n",
      "\n",
      "where τ is an atomic type or a record type. Atomic types in dom\n",
      "comprise integers, ﬂoating-point numbers, strings, etc. Records\n",
      "consist of one or multiple ﬁelds. Field i in a record has a name Ai\n",
      "and an optional multiplicity label. Repeated ﬁelds (∗) may occur\n",
      "multiple times in a record. They are interpreted as lists of values,\n",
      "i.e., the order of ﬁeld occurences in a record is signiﬁcant. Optional\n",
      "ﬁelds (?) may be missing from the record. Otherwise, a ﬁeld is\n",
      "required, i.e., must appear exactly once.\n",
      "\n",
      "To illustrate, consider Figure 2. It depicts a schema that deﬁnes a\n",
      "record type Document, representing a web document. The schema\n",
      "deﬁnition uses the concrete syntax from [21]. A Document has a re-\n",
      "quired integer DocId and optional Links, containing a list of Forward\n",
      "and Backward entries holding DocIds of other web pages. A docu-\n",
      "ment can have multiple Names, which are different URLs by which\n",
      "the document can be referenced. A Name contains a sequence of\n",
      "Code and (optional) Country pairs. Figure 2 also shows two sample\n",
      "records, r1 and r2, conforming to the schema. The record structure\n",
      "is outlined using indentation. We will use these sample records to\n",
      "explain the algorithms in the next sections. The ﬁelds deﬁned in the\n",
      "schema form a tree hierarchy. The full path of a nested ﬁeld is de-\n",
      "noted using the usual dotted notation, e.g., Name.Language.Code.\n",
      "The nested data model backs a platform-neutral, extensible\n",
      "mechanism for serializing structured data at Google. Code gen-\n",
      "eration tools produce bindings for programming languages such\n",
      "as C++ or Java. Cross-language interoperability is achieved using\n",
      "a standard binary on-the-wire representation of records, in which\n",
      "ﬁeld values are laid out sequentially as they occur in the record.\n",
      "This way, a MR program written in Java can consume records from\n",
      "a data source exposed via a C++ library. Thus, if records are stored\n",
      "in a columnar representation, assembling them fast is important for\n",
      "interoperation with MR and other data processing tools.\n",
      "\n",
      "A B C D E * * * . . . record- oriented . . . r1 r2 r1 r2 r1 r2 r1 r2 column- oriented \fFigure 2: Two sample nested records and their schema\n",
      "\n",
      "Figure 3: Column-striped representation of the sample data in Fig-\n",
      "ure 2, showing repetition levels (r) and deﬁnition levels (d)\n",
      "\n",
      "4. NESTED COLUMNAR STORAGE\n",
      "As illustrated in Figure 1, our goal is to store all values of a given\n",
      "ﬁeld consecutively to improve retrieval efﬁciency. In this section,\n",
      "we address the following challenges:\n",
      "lossless representation of\n",
      "record structure in a columnar format (Section 4.1), fast encoding\n",
      "(Section 4.2), and efﬁcient record assembly (Section 4.3).\n",
      "\n",
      "4.1 Repetition and Deﬁnition Levels\n",
      "Values alone do not convey the structure of a record. Given two\n",
      "values of a repeated ﬁeld, we do not know at what ‘level’ the value\n",
      "repeated (e.g., whether these values are from two different records,\n",
      "or two repeated values in the same record). Likewise, given a miss-\n",
      "ing optional ﬁeld, we do not know which enclosing records were\n",
      "deﬁned explicitly. We therefore introduce the concepts of repeti-\n",
      "tion and deﬁnition levels, which are deﬁned below. For reference,\n",
      "see Figure 3 which summarizes the repetition and deﬁnition levels\n",
      "for all atomic ﬁelds in our sample records.\n",
      "\n",
      "Repetition levels. Consider ﬁeld Code in Figure 2. It occurs\n",
      "three times in r1. Occurrences ‘en-us’ and ‘en’ are inside the ﬁrst\n",
      "Name, while ’en-gb’ is in the third Name. To disambiguate these\n",
      "occurrences, we attach a repetition level to each value. It tells us\n",
      "at what repeated ﬁeld in the ﬁeld’s path the value has repeated.\n",
      "The ﬁeld path Name.Language.Code contains two repeated ﬁelds,\n",
      "Name and Language. Hence, the repetition level of Code ranges\n",
      "between 0 and 2; level 0 denotes the start of a new record. Now\n",
      "suppose we are scanning record r1 top down. When we encounter\n",
      "‘en-us’, we have not seen any repeated ﬁelds, i.e., the repetition\n",
      "level is 0. When we see ‘en’, ﬁeld Language has repeated, so the\n",
      "repetition level is 2. Finally, when we encounter ‘en-gb’, Name has\n",
      "repeated most recently (Language occurred only once after Name),\n",
      "so the repetition level is 1. Thus, the repetition levels of Code val-\n",
      "ues in r1 are 0, 2, 1.\n",
      "\n",
      "Notice that the second Name in r1 does not contain any Code\n",
      "values. To determine that ‘en-gb’ occurs in the third Name and not\n",
      "in the second, we add a NULL value between ‘en’ and ‘en-gb’ (see\n",
      "Figure 3). Code is a required ﬁeld in Language, so the fact that it\n",
      "is missing implies that Language is not deﬁned. In general though,\n",
      "determining the level up to which nested records exist requires extra\n",
      "information.\n",
      "\n",
      "Deﬁnition levels. Each value of a ﬁeld with path p, esp. every\n",
      "NULL, has a deﬁnition level specifying how many ﬁelds in p that\n",
      "could be undeﬁned (because they are optional or repeated) are ac-\n",
      "\n",
      "tually present in the record. To illustrate, observe that r1 has no\n",
      "Backward links. However, ﬁeld Links is deﬁned (at level 1). To\n",
      "preserve this information, we add a NULL value with deﬁnition\n",
      "level 1 to the Links.Backward column. Similarly, the missing oc-\n",
      "currence of Name.Language.Country in r2 carries a deﬁnition level\n",
      "1, while its missing occurrences in r1 have deﬁnition levels 2 (in-\n",
      "side Name.Language) and 1 (inside Name), respectively.\n",
      "\n",
      "We use integer deﬁnition levels as opposed to is-null bits so that\n",
      "the data for a leaf ﬁeld (e.g., Name.Language.Country) contains the\n",
      "information about the occurrences of its parent ﬁelds; an example\n",
      "of how this information is used is given in Section 4.3.\n",
      "\n",
      "The encoding outlined above preserves the record structure loss-\n",
      "\n",
      "lessly. We omit the proof for space reasons.\n",
      "\n",
      "Encoding. Each column is stored as a set of blocks. Each block\n",
      "contains the repetition and deﬁnition levels (henceforth, simply\n",
      "called levels) and compressed ﬁeld values. NULLs are not stored\n",
      "explicitly as they are determined by the deﬁnition levels: any deﬁ-\n",
      "nition level smaller than the number of repeated and optional ﬁelds\n",
      "in a ﬁeld’s path denotes a NULL. Deﬁnition levels are not stored\n",
      "for values that are always deﬁned. Similarly, repetition levels are\n",
      "stored only if required; for example, deﬁnition level 0 implies rep-\n",
      "etition level 0, so the latter can be omitted. In fact, in Figure 3, no\n",
      "levels are stored for DocId. Levels are packed as bit sequences. We\n",
      "only use as many bits as necessary; for example, if the maximum\n",
      "deﬁnition level is 3, we use 2 bits per deﬁnition level.\n",
      "\n",
      "4.2 Splitting Records into Columns\n",
      "Above we presented an encoding of the record structure in a colum-\n",
      "nar format. The next challenge we address is how to produce col-\n",
      "umn stripes with repetition and deﬁnition levels efﬁciently.\n",
      "\n",
      "The base algorithm for computing repetition and deﬁnition lev-\n",
      "els is given in Appendix A. The algorithm recurses into the record\n",
      "structure and computes the levels for each ﬁeld value. As illustrated\n",
      "earlier, repetition and deﬁnition levels may need to be computed\n",
      "even if ﬁeld values are missing. Many datasets used at Google are\n",
      "sparse; it is not uncommon to have a schema with thousands of\n",
      "ﬁelds, only a hundred of which are used in a given record. Hence,\n",
      "we try to process missing ﬁelds as cheaply as possible. To produce\n",
      "column stripes, we create a tree of ﬁeld writers, whose structure\n",
      "matches the ﬁeld hierarchy in the schema. The basic idea is to\n",
      "update ﬁeld writers only when they have their own data, and not\n",
      "try to propagate parent state down the tree unless absolutely neces-\n",
      "\n",
      "DocId: 10 Links   Forward: 20   Forward: 40   Forward: 60 Name    Language      Code: 'en-us'     Country: 'us'   Language     Code: 'en'   Url: 'http://A' Name   Url: 'http://B' Name   Language     Code: 'en-gb'     Country: 'gb' r1 message Document {   required int64 DocId;   optional group Links {     repeated int64 Backward;     repeated int64 Forward; }   repeated group Name {     repeated group Language {       required string Code;       optional string Country; }     optional string Url; }} DocId: 20 Links   Backward: 10   Backward: 30   Forward:  80 Name   Url: 'http://C' r2 value r d 10 0 0 20 0 0 DocId value r d http://A 0 2 http://B 1 2 NULL 1 1 http://C 0 2 Name.Url value r d en-us 0 2 en 2 2 NULL 1 1 en-gb 1 2 NULL 0 1 Name.Language.Code Name.Language.Country Links.Backward Links.Forward value r d us 0 3 NULL 2 2 NULL 1 1 gb 1 3 NULL 0 1 value r d 20 0 2 40 1 2 60 1 2 80 0 2 value r d NULL 0 1 10 0 2 30 1 2 \fFigure 4: Complete record assembly automaton. Edges are labeled\n",
      "with repetition levels.\n",
      "\n",
      "Figure 6: Sample query, its result, and output schema\n",
      "\n",
      "preserve the enclosing structure of the ﬁeld Country. This is im-\n",
      "portant for applications that need to access, e.g., the Country ap-\n",
      "pearing in the ﬁrst Language of the second Name.\n",
      "In XPath,\n",
      "this would correspond to the ability to evaluate expressions like\n",
      "/Name[2]/Language[1]/Country.\n",
      "\n",
      "5. QUERY LANGUAGE\n",
      "Dremel’s query language is based on SQL and is designed to be\n",
      "efﬁciently implementable on columnar nested storage. Deﬁning\n",
      "the language formally is out of scope of this paper; instead, we il-\n",
      "lustrate its ﬂavor. Each SQL statement (and algebraic operators it\n",
      "translates to) takes as input one or multiple nested tables and their\n",
      "schemas and produces a nested table and its output schema. Fig-\n",
      "ure 6 depicts a sample query that performs projection, selection,\n",
      "and within-record aggregation. The query is evaluated over the ta-\n",
      "ble t = {r1, r2} from Figure 2. The ﬁelds are referenced using\n",
      "path expressions. The query produces a nested result although no\n",
      "record constructors are present in the query.\n",
      "\n",
      "To explain what the query does, consider the selection operation\n",
      "(the WHERE clause). Think of a nested record as a labeled tree,\n",
      "where each label corresponds to a ﬁeld name. The selection op-\n",
      "erator prunes away the branches of the tree that do not satisfy the\n",
      "speciﬁed conditions. Thus, only those nested records are retained\n",
      "where Name.Url is deﬁned and starts with http. Next, consider pro-\n",
      "jection. Each scalar expression in the SELECT clause emits a value\n",
      "at the same level of nesting as the most-repeated input ﬁeld used in\n",
      "that expression. So, the string concatenation expression emits Str\n",
      "values at the level of Name.Language.Code in the input schema.\n",
      "The COUNT expression illustrates within-record aggregation. The\n",
      "aggregation is done WITHIN each Name subrecord, and emits the\n",
      "number of occurrences of Name.Language.Code for each Name as\n",
      "a non-negative 64-bit integer (uint64).\n",
      "\n",
      "The language supports nested subqueries, inter and intra-record\n",
      "aggregation, top-k, joins, user-deﬁned functions, etc; some of these\n",
      "features are exempliﬁed in the experimental section.\n",
      "\n",
      "6. QUERY EXECUTION\n",
      "We discuss the core ideas in the context of a read-only system, for\n",
      "simplicity. Many Dremel queries are one-pass aggregations; there-\n",
      "fore, we focus on explaining those and use them for experiments\n",
      "in the next section. We defer the discussion of joins, indexing, up-\n",
      "dates, etc. to future work.\n",
      "\n",
      "Tree architecture. Dremel uses a multi-level serving tree to\n",
      "execute queries (see Figure 7). A root server receives incoming\n",
      "queries, reads metadata from the tables, and routes the queries to\n",
      "the next level in the serving tree. The leaf servers communicate\n",
      "\n",
      "Figure 5: Automaton for assembling records from two ﬁelds, and\n",
      "the records it produces\n",
      "\n",
      "sary. To do that, child writers inherit the levels from their parents.\n",
      "A child writer synchronizes to its parent’s levels whenever a new\n",
      "value is added.\n",
      "\n",
      "4.3 Record Assembly\n",
      "Assembling records from columnar data efﬁciently is critical for\n",
      "record-oriented data processing tools (e.g., MR). Given a subset of\n",
      "ﬁelds, our goal is to reconstruct the original records as if they con-\n",
      "tained just the selected ﬁelds, with all other ﬁelds stripped away.\n",
      "The key idea is this: we create a ﬁnite state machine (FSM) that\n",
      "reads the ﬁeld values and levels for each ﬁeld, and appends the val-\n",
      "ues sequentially to the output records. An FSM state corresponds\n",
      "to a ﬁeld reader for each selected ﬁeld. State transitions are labeled\n",
      "with repetition levels. Once a reader fetches a value, we look at the\n",
      "next repetition level to decide what next reader to use. The FSM is\n",
      "traversed from the start to end state once for each record.\n",
      "\n",
      "Figure 4 shows an FSM that reconstructs the complete records\n",
      "in our running example. The start state is DocId. Once a DocId\n",
      "value is read, the FSM transitions to Links.Backward. After all\n",
      "repeated Backward values have been drained, the FSM jumps to\n",
      "Links.Forward, etc. The details of the record assembly algorithm\n",
      "are in Appendix B.\n",
      "\n",
      "To sketch how FSM transitions are constructed, let l be the next\n",
      "repetition level returned by the current ﬁeld reader for ﬁeld f . Start-\n",
      "ing at f in the schema tree, we ﬁnd its ancestor that repeats at level l\n",
      "and select the ﬁrst leaf ﬁeld n inside that ancestor. This gives us an\n",
      "FSM transition (f, l) → n. For example, let l = 1 be the next repe-\n",
      "tition level read by f = Name.Language.Country. Its ancestor with\n",
      "repetition level 1 is Name, whose ﬁrst leaf ﬁeld is n = Name.Url.\n",
      "The details of the FSM construction algorithm are in Appendix C.\n",
      "If only a subset of ﬁelds need to be retrieved, we construct a\n",
      "simpler FSM that is cheaper to execute. Figure 5 depicts an FSM\n",
      "for reading the ﬁelds DocId and Name.Language.Country. The\n",
      "ﬁgure shows the output records s1 and s2 produced by the au-\n",
      "tomaton. Notice that our encoding and the assembly algorithm\n",
      "\n",
      "Name.Language.Country Name.Language.Code Links.Backward Links.Forward Name.Url DocId 1 0 1 0 0,1,2 2 0,1 1 0 0 DocId Name.Language.Country 1,2 0 0 DocId: 10 Name   Language      Country: 'us'   Language Name   Language     Country: 'gb' DocId: 20 Name s1 s2 Id: 10 Name   Cnt: 2   Language      Str: 'http://A,en-us'     Str: 'http://A,en' Name   Cnt: 0 t1 SELECT DocId AS Id,   COUNT(Name.Language.Code) WITHIN Name AS Cnt,   Name.Url + ',' + Name.Language.Code AS Str FROM t WHERE REGEXP(Name.Url, '^http') AND DocId < 20; message QueryResult {   required int64 Id;   repeated group Name {     optional uint64 Cnt;     repeated group Language {       optional string Str; }}} \fFigure 7: System architecture and execution inside a server node\n",
      "\n",
      "with the storage layer or access the data on local disk. Consider a\n",
      "simple aggregation query below:\n",
      "\n",
      "SELECT A, COUNT(B) FROM T GROUP BY A\n",
      "\n",
      "When the root server receives the above query, it determines all\n",
      "tablets, i.e., horizontal partitions of the table, that comprise T and\n",
      "rewrites the query as follows:\n",
      "SELECT A, SUM(c) FROM (R1\n",
      "1, . . . , R1\n",
      "\n",
      "n) GROUP BY A\n",
      "n are the results of queries sent to the nodes\n",
      "\n",
      "1 UNION ALL ... R1\n",
      "\n",
      "Tables R1\n",
      "\n",
      "i GROUP BY A\n",
      "\n",
      "1, . . . , n at level 1 of the serving tree:\n",
      "R1\n",
      "\n",
      "i = SELECT A, COUNT(B) AS c FROM T 1\n",
      "T 1\n",
      "i\n",
      "\n",
      "is a disjoint partition of tablets in T processed by server i\n",
      "at level 1. Each serving level performs a similar rewriting. Ulti-\n",
      "mately, the queries reach the leaves, which scan the tablets in T in\n",
      "parallel. On the way up, intermediate servers perform a parallel ag-\n",
      "gregation of partial results. The execution model presented above\n",
      "is well-suited for aggregation queries returning small and medium-\n",
      "sized results, which are a very common class of interactive queries.\n",
      "Large aggregations and other classes of queries may need to rely\n",
      "on execution mechanisms known from parallel DBMSs and MR.\n",
      "\n",
      "Query dispatcher. Dremel is a multi-user system, i.e., usually\n",
      "several queries are executed simultaneously. A query dispatcher\n",
      "schedules queries based on their priorities and balances the load. Its\n",
      "other important role is to provide fault tolerance when one server\n",
      "becomes much slower than others or a tablet replica becomes un-\n",
      "reachable.\n",
      "\n",
      "The amount of data processed in each query is often larger than\n",
      "the number of processing units available for execution, which we\n",
      "call slots. A slot corresponds to an execution thread on a leaf server.\n",
      "For example, a system of 3,000 leaf servers each using 8 threads\n",
      "has 24,000 slots. So, a table spanning 100,000 tablets can be pro-\n",
      "cessed by assigning about 5 tablets to each slot. During query ex-\n",
      "ecution, the query dispatcher computes a histogram of tablet pro-\n",
      "cessing times. If a tablet takes a disproportionately long time to\n",
      "process, it reschedules it on another server. Some tablets may need\n",
      "to be redispatched multiple times.\n",
      "\n",
      "The leaf servers read stripes of nested data in columnar represen-\n",
      "tation. The blocks in each stripe are prefetched asynchronously;\n",
      "the read-ahead cache typically achieves hit rates of 95%. Tablets\n",
      "are usually three-way replicated. When a leaf server cannot access\n",
      "one tablet replica, it falls over to another replica.\n",
      "\n",
      "The query dispatcher honors a parameter that speciﬁes the min-\n",
      "imum percentage of tablets that must be scanned before returning\n",
      "a result. As we demonstrate shortly, setting such parameter to a\n",
      "lower value (e.g., 98% instead of 100%) can often speed up execu-\n",
      "\n",
      "Figure 8: Datasets used in the experimental study\n",
      "\n",
      "tion signiﬁcantly, especially when using smaller replication factors.\n",
      "Each server has an internal execution tree, as depicted on the\n",
      "right-hand side of Figure 7. The internal tree corresponds to a phys-\n",
      "ical query execution plan, including evaluation of scalar expres-\n",
      "sions. Optimized, type-speciﬁc code is generated for most scalar\n",
      "functions. An execution plan for project-select-aggregate queries\n",
      "consists of a set of iterators that scan input columns in lockstep and\n",
      "emit results of aggregates and scalar functions annotated with the\n",
      "correct repetition and deﬁnition levels, bypassing record assembly\n",
      "entirely during query execution. For details, see Appendix D.\n",
      "\n",
      "Some Dremel queries, such as top-k and count-distinct, return\n",
      "\n",
      "approximate results using known one-pass algorithms (e.g., [4]).\n",
      "\n",
      "7. EXPERIMENTS\n",
      "In this section we evaluate Dremel’s performance on several\n",
      "datasets used at Google, and examine the effectiveness of colum-\n",
      "nar storage for nested data. The properties of the datasets used\n",
      "in our study are summarized in Figure 8. In uncompressed, non-\n",
      "replicated form the datasets occupy about a petabyte of space. All\n",
      "tables are three-way replicated, except one two-way replicated ta-\n",
      "ble, and contain from 100K to 800K tablets of varying sizes. We\n",
      "start by examining the basic data access characteristics on a single\n",
      "machine, then show how columnar storage beneﬁts MR execution,\n",
      "and ﬁnally focus on Dremel’s performance. The experiments were\n",
      "conducted on system instances running in two data centers next to\n",
      "many other applications, during regular business operation. Un-\n",
      "less speciﬁed otherwise, execution times were averaged across ﬁve\n",
      "runs. Table and ﬁeld names used below are anonymized.\n",
      "\n",
      "Local disk. In the ﬁrst experiment, we examine performance\n",
      "tradeoffs of columnar vs. record-oriented storage, scanning a 1GB\n",
      "fragment of table T1 containing about 300K rows (see Figure 9).\n",
      "The data is stored on a local disk and takes about 375MB in com-\n",
      "pressed columnar representation. The record-oriented format uses\n",
      "heavier compression yet yields about the same size on disk. The\n",
      "experiment was done on a dual-core Intel machine with a disk pro-\n",
      "viding 70MB/s read bandwidth. All reported times are cold; OS\n",
      "cache was ﬂushed prior to each scan.\n",
      "\n",
      "The ﬁgure shows ﬁve graphs, illustrating the time it takes to read\n",
      "and uncompress the data, and assemble and parse the records, for a\n",
      "subset of the ﬁelds. Graphs (a)-(c) outline the results for columnar\n",
      "storage. Each data point in these graphs was obtained by averaging\n",
      "the measurements over 30 runs, in each of which a set of columns of\n",
      "a given cardinality was chosen at random. Graph (a) shows read-\n",
      "ing and decompression time. Graph (b) adds the time needed to\n",
      "assemble nested records from columns. Graph (c) shows how long\n",
      "it takes to parse the records into strongly typed C++ data structures.\n",
      "Graphs (d)-(e) depict the time for accessing the data on record-\n",
      "oriented storage. Graph (d) shows reading and decompression time.\n",
      "A bulk of the time is spent in decompression; in fact, the com-\n",
      "pressed data can be read from the disk in about half the time. As\n",
      "\n",
      "query execution tree . . . . . . . . . storage layer (e.g., GFS) . . . . . . . . . leaf servers (with local  storage) intermediate servers root server client Table name Number of records Size (unrepl., compressed) Number of fields Data center Repl. factor T1 85 billion 87 TB 270 A 3× T2 24 billion 13 TB 530 A 3× T3 4 billion 70 TB 1200 A 3× T4 1+ trillion 105 TB 50 B 3× T5 1+ trillion 20 TB 30 B 2× \fFigure 9: Performance breakdown when reading from a local disk\n",
      "(300K-record fragment of Table T1)\n",
      "\n",
      "Graph (e) indicates, parsing adds another 50% on top of reading\n",
      "and decompression time. These costs are paid for all ﬁelds, includ-\n",
      "ing the ones that are not needed.\n",
      "\n",
      "The main takeaways of this experiment are the following: when\n",
      "few columns are read, the gains of columnar representation are of\n",
      "about an order of magnitude. Retrieval time for columnar nested\n",
      "data grows linearly with the number of ﬁelds. Record assembly and\n",
      "parsing are expensive, each potentially doubling the execution time.\n",
      "We observed similar trends on other datasets. A natural question\n",
      "to ask is where the top and bottom graphs cross, i.e., record-wise\n",
      "storage starts outperforming columnar storage. In our experience,\n",
      "the crossover point often lies at dozens of ﬁelds but it varies across\n",
      "datasets and depends on whether or not record assembly is required.\n",
      "\n",
      "MR and Dremel. Next we illustrate a MR and Dremel exe-\n",
      "cution on columnar vs. record-oriented data. We consider a case\n",
      "where a single ﬁeld is accessed, i.e., the performance gains are\n",
      "most pronounced. Execution times for multiple columns can be\n",
      "extrapolated using the results of Figure 9. In this experiment, we\n",
      "count the average number of terms in a ﬁeld txtField of table T1.\n",
      "MR execution is done using the following Sawzall [20] program:\n",
      "numRecs: table sum of int;\n",
      "numWords: table sum of int;\n",
      "emit numRecs <- 1;\n",
      "emit numWords <- CountWords(input.txtField);\n",
      "\n",
      "The number of records is stored in the variable numRecs. For\n",
      "each record, numWords is incremented by the number of terms\n",
      "in input.txtField returned by the CountWords function. After the\n",
      "program runs, the average term frequency can be computed as\n",
      "numWords/numRecs. In SQL, this computation is expressed as:\n",
      "\n",
      "Q1: SELECT SUM(CountWords(txtField)) / COUNT(*) FROM T1\n",
      "\n",
      "Figure 10 shows the execution times of two MR jobs and Dremel\n",
      "on a logarithmic scale. Both MR jobs are run on 3000 work-\n",
      "ers. Similarly, a 3000-node Dremel instance is used to execute\n",
      "Query Q1. Dremel and MR-on-columns read about 0.5TB of com-\n",
      "pressed columnar data vs. 87TB read by MR-on-records. As the\n",
      "ﬁgure illustrates, MR gains an order of magnitude in efﬁciency by\n",
      "switching from record-oriented to columnar storage (from hours to\n",
      "minutes). Another order of magnitude is achieved by using Dremel\n",
      "(going from minutes to seconds).\n",
      "\n",
      "Serving tree topology. In the next experiment, we show the\n",
      "impact of the serving tree depth on query execution times. We\n",
      "consider two GROUP BY queries on Table T2, each executed using\n",
      "\n",
      "Figure 10: MR and Dremel execution on columnar vs. record-\n",
      "oriented storage (3000 nodes, 85 billion records)\n",
      "\n",
      "Figure 11: Execution time as a function of serving tree levels for\n",
      "two aggregation queries on T2\n",
      "\n",
      "a single scan over the data. Table T2 contains 24 billion nested\n",
      "records. Each record has a repeated ﬁeld item containing a numeric\n",
      "amount. The ﬁeld item.amount repeats about 40 billion times in the\n",
      "dataset. The ﬁrst query sums up the item amount by country:\n",
      "\n",
      "Q2: SELECT country, SUM(item.amount) FROM T2\n",
      "\n",
      "GROUP BY country\n",
      "\n",
      "It returns a few hundred records and reads roughly 60GB of com-\n",
      "pressed data from disk. The second query performs a GROUP BY\n",
      "on a text ﬁeld domain with a selection condition. It reads about\n",
      "180GB and produces around 1.1 million distinct domains:\n",
      "\n",
      "Q3: SELECT domain, SUM(item.amount) FROM T2\n",
      "\n",
      "WHERE domain CONTAINS ’.net’\n",
      "GROUP BY domain\n",
      "\n",
      "Figure 11 shows the execution times for each query as a function\n",
      "of the server topology. In each topology, the number of leaf servers\n",
      "is kept constant at 2900 so that we can assume the same cumulative\n",
      "scan speed. In the 2-level topology (1:2900), a single root server\n",
      "communicates directly with the leaf servers. For 3 levels, we use\n",
      "a 1:100:2900 setup, i.e., an extra level of 100 intermediate servers.\n",
      "The 4-level topology is 1:10:100:2900.\n",
      "\n",
      "Query Q2 runs in 3 seconds when 3 levels are used in the serv-\n",
      "ing tree and does not beneﬁt much from an extra level.\n",
      "In con-\n",
      "trast, the execution time of Q3 is halved due to increased paral-\n",
      "lelism. At 2 levels, Q3 is off the chart, as the root server needs\n",
      "to aggregate near-sequentially the results received from thousands\n",
      "of nodes. This experiment illustrates how aggregations returning\n",
      "many groups beneﬁt from multi-level serving trees.\n",
      "\n",
      "Per-tablet histograms. To drill deeper into what happens dur-\n",
      "ing query execution consider Figure 12. The ﬁgure shows how fast\n",
      "tablets get processed by the leaf servers for a speciﬁc run of Q2 and\n",
      "Q3. The time is measured starting at the point when a tablet got\n",
      "scheduled for execution in an available slot, i.e., excludes the time\n",
      "spent waiting in the job queue. This measurement methodology\n",
      "factors out the effects of other queries that are executing simulta-\n",
      "neously. The area under each histogram corresponds to 100%. As\n",
      "the ﬁgure indicates, 99% of Q2 (or Q3) tablets are processed under\n",
      "one second (or two seconds).\n",
      "\n",
      "!\"#\"$\"%\"&\"’!\"’#\"’$\"’%\"’&\"#!\"’\"#\"(\"$\")\"%\"*\"&\"+\"’!\"columns records objects from records from columns (a) read +    decompress (b) assemble       records (c) parse as      objects (d) read +   decompress (e) parse as      objects time (sec) number of fields !\"!#\"!##\"!###\"!####\"$%&’()*’+,\"$%&)*-./0,\"1’(/(-\"execution time (sec) !\"#!\"$!\"%!\"&!\"’!\"(!\")$\")%\"$\"*+,+*-\"%\"*+,+*-\"&\"*+,+*-\"execution time (sec) \fFigure 12: Histograms of processing times\n",
      "\n",
      "Figure 14: Query Q5 on T5 illustrating stragglers at 2× replication\n",
      "\n",
      "Figure 13: Scaling the system from 1000 to 4000 nodes using a\n",
      "top-k query Q5 on a trillion-row table T4\n",
      "\n",
      "Within-record aggregation. As another experiment, we ex-\n",
      "amine the performance of Query Q4 run on Table T3. The query\n",
      "illustrates within-record aggregation:\n",
      "it counts all records where\n",
      "the sum of a.b.c.d values occurring in the record are larger than\n",
      "the sum of a.b.p.q.r values. The ﬁelds repeat at different levels of\n",
      "nesting. Due to column striping only 13GB (out of 70TB) are read\n",
      "from disk and the query completes in 15 seconds. Without support\n",
      "for nesting, running this query on T3 would be grossly expensive.\n",
      "\n",
      "Q4 : SELECT COUNT(c1 > c2) FROM\n",
      "\n",
      "(SELECT SUM(a.b.c.d) WITHIN RECORD AS c1,\n",
      "SUM(a.b.p.q.r) WITHIN RECORD AS c2\n",
      "FROM T3)\n",
      "\n",
      "Scalability. The following experiment illustrates the scalability\n",
      "of the system on a trillion-record table. Query Q5 shown below\n",
      "selects top-20 aid’s and their number of occurrences in Table T4.\n",
      "The query scans 4.2TB of compressed data.\n",
      "\n",
      "Q5: SELECT TOP(aid, 20), COUNT(*) FROM T4\n",
      "WHERE bid = {value1} AND cid = {value2}\n",
      "\n",
      "The query was executed using four conﬁgurations of the sys-\n",
      "tem, ranging from 1000 to 4000 nodes. The execution times are\n",
      "in Figure 13. In each run, the total expended CPU time is nearly\n",
      "identical, at about 300K seconds, whereas the user-perceived time\n",
      "decreases near-linearly with the growing size of the system. This\n",
      "result suggests that a larger system can be just as effective in terms\n",
      "of resource usage as a smaller one, yet allows faster execution.\n",
      "\n",
      "Stragglers. Our last experiment shows the impact of stragglers.\n",
      "Query Q6 below is run on a trillion-row table T5. In contrast to\n",
      "the other datasets, T5 is two-way replicated. Hence, the likelihood\n",
      "of stragglers slowing the execution is higher since there are fewer\n",
      "opportunities to reschedule the work.\n",
      "\n",
      "Q6: SELECT COUNT(DISTINCT a) FROM T5\n",
      "\n",
      "Figure 15: Query response time distribution in a monthly workload\n",
      "\n",
      "sion ratio for the retrieved ﬁeld is about 10. As indicated in Fig-\n",
      "ure 14, the processing time for 99% of the tablets is below 5 sec-\n",
      "onds per tablet per slot. However, a small fraction of the tablets\n",
      "take a lot longer, slowing down the query response time from less\n",
      "than a minute to several minutes, when executed on a 2500 node\n",
      "system. The next section summarizes our experimental ﬁndings\n",
      "and the lessons we learned.\n",
      "\n",
      "8. OBSERVATIONS\n",
      "Dremel scans quadrillions of records per month. Figure 15 shows\n",
      "the query response time distribution in a typical monthly workload\n",
      "of one Dremel system, on a logarithmic scale. As the ﬁgure indi-\n",
      "cates, most queries are processed under 10 seconds, well within the\n",
      "interactive range. Some queries achieve a scan throughput close\n",
      "to 100 billion records per second on a shared cluster, and even\n",
      "higher on dedicated machines. The experimental data presented\n",
      "above suggests the following observations:\n",
      "\n",
      "• Scan-based queries can be executed at interactive speeds on\n",
      "\n",
      "disk-resident datasets of up to a trillion records.\n",
      "\n",
      "• Near-linear scalability in the number of columns and servers\n",
      "is achievable for systems containing thousands of nodes.\n",
      "• MR can beneﬁt from columnar storage just like a DBMS.\n",
      "• Record assembly and parsing are expensive. Software layers\n",
      "(beyond the query processing layer) need to be optimized to\n",
      "directly consume column-oriented data.\n",
      "\n",
      "• MR and query processing can be used in a complementary\n",
      "\n",
      "fashion; one layer’s output can feed another’s input.\n",
      "\n",
      "• In a multi-user environment, a larger system can beneﬁt from\n",
      "economies of scale while offering a qualitatively better user\n",
      "experience.\n",
      "\n",
      "• If trading speed against accuracy is acceptable, a query can\n",
      "be terminated much earlier and yet see most of the data.\n",
      "• The bulk of a web-scale dataset can be scanned fast. Getting\n",
      "\n",
      "Query Q6 reads over 1TB of compressed data. The compres-\n",
      "\n",
      "to the last few percent within tight time bounds is hard.\n",
      "\n",
      "!\"!#$\"!#%\"!#&\"!#’\"(\"(#$\"(#%\"(#&\"!\"!#)\"(\"(#)\"$\"$#)\"*\"percentage of processed tablets processing time per tablet (sec) Q3 Q2 !\"#!\"$!!\"$#!\"%!!\"%#!\"$!!!\"%!!!\"&!!!\"’!!!\"execution time (sec) number of leaf servers !\"!#$\"!#%\"!#&\"!#’\"!#(\"!#)\"!\"%\"’\")\"*\"$!\"$%\"$’\"$)\"percentage of processed tablets processing time per tablet (sec) stragglers !\"#\"$!\"$#\"%!\"%#\"&!\"$\"$!\"$!!\"$!!!\"execution time (sec) percentage of queries \fDremel’s codebase is dense; it comprises less than 100K lines of\n",
      "\n",
      "12. REFERENCES\n",
      "\n",
      "C++, Java, and Python code.\n",
      "\n",
      "9. RELATED WORK\n",
      "The MapReduce (MR) [12] framework was designed to address the\n",
      "challenges of large-scale computing in the context of long-running\n",
      "batch jobs. Like MR, Dremel provides fault tolerant execution, a\n",
      "ﬂexible data model, and in situ data processing capabilities. The\n",
      "success of MR led to a wide range of third-party implementations\n",
      "(notably open-source Hadoop [15]), and a number of hybrid sys-\n",
      "tems that combine parallel DBMSs with MR, offered by vendors\n",
      "like Aster, Cloudera, Greenplum, and Vertica. HadoopDB [3] is\n",
      "a research system in this hybrid category. Recent articles [13, 22]\n",
      "contrast MR and parallel DBMSs. Our work emphasizes the com-\n",
      "plementary nature of both paradigms.\n",
      "\n",
      "Dremel is designed to operate at scale. Although it is conceivable\n",
      "that parallel DBMSs can be made to scale to thousands of nodes,\n",
      "we are not aware of any published work or industry reports that at-\n",
      "tempted that. Neither are we familiar with prior literature studying\n",
      "MR on columnar storage.\n",
      "\n",
      "Our columnar representation of nested data builds on ideas that\n",
      "date back several decades: separation of structure from content\n",
      "and transposed representation. A recent review of work on col-\n",
      "umn stores, incl. compression and query processing, can be found\n",
      "in [1]. Many commercial DBMSs support storage of nested data\n",
      "using XML (e.g., [19]). XML storage schemes attempt to separate\n",
      "the structure from the content but face more challenges due to the\n",
      "ﬂexibility of the XML data model. One system that uses columnar\n",
      "XML representation is XMill [17]. XMill is a compression tool.\n",
      "It stores the structure for all ﬁelds combined and is not geared for\n",
      "selective retrieval of columns.\n",
      "\n",
      "The data model used in Dremel is a variation of the com-\n",
      "plex value models and nested relational models discussed in [2].\n",
      "Dremel’s query language builds on the ideas from [9], which intro-\n",
      "duced a language that avoids restructuring when accessing nested\n",
      "data. In contrast, restructuring is usually required in XQuery and\n",
      "object-oriented query languages, e.g., using nested for-loops and\n",
      "constructors. We are not aware of practical implementations of [9].\n",
      "A recent SQL-like language operating on nested data is Pig [18].\n",
      "Other systems for parallel data processing include Scope [6] and\n",
      "DryadLINQ [23], and are discussed in more detail in [7].\n",
      "\n",
      "10. CONCLUSIONS\n",
      "We presented Dremel, a distributed system for interactive analy-\n",
      "sis of large datasets. Dremel is a custom, scalable data manage-\n",
      "ment solution built from simpler components. It complements the\n",
      "MR paradigm. We discussed its performance on trillion-record,\n",
      "multi-terabyte datasets of real data. We outlined the key aspects\n",
      "of Dremel, including its storage format, query language, and exe-\n",
      "cution. In the future, we plan to cover in more depth such areas as\n",
      "formal algebraic speciﬁcation, joins, extensibility mechanisms, etc.\n",
      "\n",
      "11. ACKNOWLEDGEMENTS\n",
      "Dremel has beneﬁted greatly from the input of many engineers and\n",
      "interns at Google, in particular Craig Chambers, Ori Gershoni, Ra-\n",
      "jeev Byrisetti, Leon Wong, Erik Hendriks, Erika Rice Scherpelz,\n",
      "Charlie Garrett, Idan Avraham, Rajesh Rao, Andy Kreling, Li Yin,\n",
      "Madhusudan Hosaagrahara, Dan Belov, Brian Bershad, Lawrence\n",
      "You, Rongrong Zhong, Meelap Shah, and Nathan Bales.\n",
      "\n",
      "[1] D. J. Abadi, P. A. Boncz, and S. Harizopoulos.\n",
      "\n",
      "Column-Oriented Database Systems. VLDB, 2(2), 2009.\n",
      "\n",
      "[2] S. Abiteboul, R. Hull, and V. Vianu. Foundations of\n",
      "\n",
      "Databases. Addison Wesley, 1995.\n",
      "\n",
      "[3] A. Abouzeid, K. Bajda-Pawlikowski, D. J. Abadi, A. Rasin,\n",
      "and A. Silberschatz. HadoopDB: An Architectural Hybrid of\n",
      "MapReduce and DBMS Technologies for Analytical\n",
      "Workloads. VLDB, 2(1), 2009.\n",
      "\n",
      "[4] Z. Bar-Yossef, T. S. Jayram, R. Kumar, D. Sivakumar, and\n",
      "\n",
      "L. Trevisan. Counting Distinct Elements in a Data Stream. In\n",
      "RANDOM, pages 1–10, 2002.\n",
      "\n",
      "[5] L. A. Barroso and U. H¨olzle. The Datacenter as a Computer:\n",
      "An Introduction to the Design of Warehouse-Scale Machines.\n",
      "Morgan & Claypool Publishers, 2009.\n",
      "\n",
      "[6] R. Chaiken, B. Jenkins, P.-A. Larson, B. Ramsey, D. Shakib,\n",
      "S. Weaver, and J. Zhou. SCOPE: Easy and Efﬁcient Parallel\n",
      "Processing of Massive Data Sets. VLDB, 1(2), 2008.\n",
      "[7] C. Chambers, A. Raniwala, F. Perry, S. Adams, R. Henry,\n",
      "R. Bradshaw, and N. Weizenbaum. FlumeJava: Easy,\n",
      "Efﬁcient Data-Parallel Pipelines. In PLDI, 2010.\n",
      "[8] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A.\n",
      "\n",
      "Wallach, M. Burrows, T. Chandra, A. Fikes, and R. Gruber.\n",
      "Bigtable: A Distributed Storage System for Structured Data.\n",
      "In OSDI, 2006.\n",
      "\n",
      "[9] L. S. Colby. A Recursive Algebra and Query Optimization\n",
      "\n",
      "for Nested Relations. SIGMOD Rec., 18(2), 1989.\n",
      "[10] G. Czajkowski. Sorting 1PB with MapReduce. Ofﬁcial\n",
      "\n",
      "Google Blog, Nov. 2008. At http://googleblog.blogspot.com/\n",
      "2008/11/sorting-1pb-with-mapreduce.html.\n",
      "\n",
      "[11] J. Dean. Challenges in Building Large-Scale Information\n",
      "Retrieval Systems: Invited Talk. In WSDM, 2009.\n",
      "[12] J. Dean and S. Ghemawat. MapReduce: Simpliﬁed Data\n",
      "\n",
      "Processing on Large Clusters. In OSDI, 2004.\n",
      "\n",
      "[13] J. Dean and S. Ghemawat. MapReduce: a Flexible Data\n",
      "\n",
      "Processing Tool. Commun. ACM, 53(1), 2010.\n",
      "\n",
      "[14] S. Ghemawat, H. Gobioff, and S.-T. Leung. The Google File\n",
      "\n",
      "System. In SOSP, 2003.\n",
      "\n",
      "[15] Hadoop Apache Project. http://hadoop.apache.org.\n",
      "[16] Hive. http://wiki.apache.org/hadoop/Hive, 2009.\n",
      "[17] H. Liefke and D. Suciu. XMill: An Efﬁcient Compressor for\n",
      "\n",
      "XML Data. In SIGMOD, 2000.\n",
      "\n",
      "[18] C. Olston, B. Reed, U. Srivastava, R. Kumar, and\n",
      "\n",
      "A. Tomkins. Pig Latin: a Not-so-Foreign Language for Data\n",
      "Processing. In SIGMOD, 2008.\n",
      "\n",
      "[19] P. E. O’Neil, E. J. O’Neil, S. Pal, I. Cseri, G. Schaller, and\n",
      "N. Westbury. ORDPATHs: Insert-Friendly XML Node\n",
      "Labels. In SIGMOD, 2004.\n",
      "\n",
      "[20] R. Pike, S. Dorward, R. Griesemer, and S. Quinlan.\n",
      "\n",
      "Interpreting the Data: Parallel Analysis with Sawzall.\n",
      "Scientiﬁc Programming, 13(4), 2005.\n",
      "\n",
      "[21] Protocol Buffers: Developer Guide. Available at\n",
      "\n",
      "http://code.google.com/apis/protocolbuffers/docs/overview.html.\n",
      "\n",
      "[22] M. Stonebraker, D. Abadi, D. J. DeWitt, S. Madden,\n",
      "\n",
      "E. Paulson, A. Pavlo, and A. Rasin. MapReduce and Parallel\n",
      "DBMSs: Friends or Foes? Commun. ACM, 53(1), 2010.\n",
      "[23] Y. Yu, M. Isard, D. Fetterly, M. Budiu, ´U. Erlingsson, P. K.\n",
      "\n",
      "Gunda, and J. Currey. DryadLINQ: A System for\n",
      "General-Purpose Distributed Data-Parallel Computing Using\n",
      "a High-Level Language. In OSDI, 2008.\n",
      "\n",
      "\fFigure 16: Algorithm for dissecting a record into columns\n",
      "\n",
      "APPENDIX\n",
      "\n",
      "A. COLUMN-STRIPING ALGORITHM\n",
      "The algorithm for decomposing a record into columns is shown\n",
      "in Figure 16. Procedure DissectRecord is passed an instance of a\n",
      "RecordDecoder, which is used to traverse binary-encoded records.\n",
      "FieldWriters form a tree hierarchy isomorphic to that of the input\n",
      "schema. The root FieldWriter is passed to the algorithm for each\n",
      "new record, with repetitionLevel set to 0. The primary job of the\n",
      "DissectRecord procedure is to maintain the current repetitionLevel.\n",
      "The current deﬁnitionLevel is uniquely determined by the tree posi-\n",
      "tion of the current writer, as the sum of the number of optional and\n",
      "repeated ﬁelds in the ﬁeld’s path.\n",
      "\n",
      "The while-loop of the algorithm (Line 5) iterates over all atomic\n",
      "and record-valued ﬁelds contained in a given record. The set\n",
      "seenFields tracks whether or not a ﬁeld has been seen in the\n",
      "record.\n",
      "It is used to determine what ﬁeld has repeated most re-\n",
      "cently. The child repetition level chRepetitionLevel is set to that\n",
      "of the most recently repeated ﬁeld or else defaults to its parent’s\n",
      "level (Lines 9-13). The procedure is invoked recursively on nested\n",
      "records (Line 18).\n",
      "\n",
      "In Section 4.2 we sketched how FieldWriters accumulate levels\n",
      "and propagate them lazily to lower-level writers. This is done as\n",
      "follows: each non-leaf writer keeps a sequence of (repetition, def-\n",
      "inition) levels. Each writer also has a ‘version’ number associated\n",
      "with it. Simply stated, a writer version is incremented by one when-\n",
      "ever a level is added. It is sufﬁcient for children to remember the\n",
      "last parent’s version they synced. If a child writer ever gets its own\n",
      "(non-null) value, it synchronizes its state with the parent by fetch-\n",
      "ing new levels, and only then adds the new data.\n",
      "\n",
      "Because input data can have thousands of ﬁelds and millions\n",
      "records, it is not feasible to store all levels in memory. Some levels\n",
      "may be temporarily stored in a ﬁle on disk. For a lossless encoding\n",
      "of empty (sub)records, non-atomic ﬁelds (such as Name.Language\n",
      "in Figure 2) may need to have column stripes of their own, contain-\n",
      "ing only levels but no non-NULL values.\n",
      "\n",
      "B. RECORD ASSEMBLY ALGORITHM\n",
      "In their on-the-wire representation, records are laid out as pairs of\n",
      "\n",
      "Figure 17: Algorithm for assembling a record from columns\n",
      "\n",
      "a ﬁeld identiﬁer followed by a ﬁeld value. Nested records can be\n",
      "thought of as having an ‘opening tag’ and a ‘closing tag’, similar to\n",
      "XML (actual binary encoding may differ, see [21] for details). In\n",
      "the following, writing opening tags is referred to as ‘starting’ the\n",
      "record, and writing closing tags is called ’ending’ it.\n",
      "\n",
      "AssembleRecord procedure takes as input a set of FieldReaders\n",
      "and (implicitly) the FSM with state transitions between the readers.\n",
      "Variable reader holds the current FieldReader in the main routine\n",
      "(Line 4). Variable lastReader holds the last reader whose value\n",
      "we appended to the record and is available to all three procedures\n",
      "shown in Figure 17. The main while-loop is at Line 5. We fetch\n",
      "the next value from the current reader. If the value is not NULL,\n",
      "which is determined by looking at its deﬁnition level, we synchro-\n",
      "nize the record being assembled to the record structure of the cur-\n",
      "rent reader in the method MoveToLevel, and append the ﬁeld value\n",
      "to the record. Otherwise, we merely adjust the record structure\n",
      "without appending any value—which needs to be done if empty\n",
      "records are present. On Line 12, we use a ‘full deﬁnition level’.\n",
      "Recall that the deﬁnition level factors out required ﬁelds (only re-\n",
      "peated and optional ﬁelds are counted). Full deﬁnition level takes\n",
      "all ﬁelds into account.\n",
      "\n",
      "Procedure MoveToLevel transitions the record from the state of\n",
      "the lastReader to that of the nextReader (see Line 22). For exam-\n",
      "ple, suppose the lastReader corresponds to Links.Backward in Fig-\n",
      "ure 2 and nextReader is Name.Language.Code. The method ends\n",
      "the nested record Links and starts new records Name and Language,\n",
      "in that order. Procedure ReturnsToLevel (Line 30) is a counterpart\n",
      "of MoveToLevel that only ends current records without starting any\n",
      "new ones.\n",
      "\n",
      " 1 procedure DissectRecord(RecordDecoder decoder,  2             FieldWriter writer, int repetitionLevel):  3   Add current repetitionLevel and definition level to  writer  4   seenFields = {} // empty set of integers    5   while decoder has more field values  6     FieldWriter chWriter =  7       child of writer for field read by decoder  8     int chRepetitionLevel = repetitionLevel  9     if set seenFields contains field ID of chWriter 10       chRepetitionLevel = tree depth of chWriter 11     else 12       Add field ID of chWriter to seenFields 13     end if 14     if chWriter corresponds to an atomic field 15       Write value of current field read by decoder 16              using chWriter at chRepetitionLevel 17     else 18       DissectRecord(new RecordDecoder for nested record 19                  read by decoder, chWriter, chRepetitionLevel) 20     end if 21   end while  22 end procedure  1 Record AssembleRecord(FieldReaders[] readers):  2   record = create a new record  3   lastReader = select the root field reader in readers  4   reader = readers[0]  5   while reader has data  6     Fetch next value from reader  7     if current value is not NULL  8       MoveToLevel(tree level of reader, reader)  9       Append reader's value to record 10     else 11       MoveToLevel(full definition level of reader, reader) 12     end if 13     reader = reader that FSM transitions to 14               when reading next repetition level from reader  15     ReturnToLevel(tree level of reader) 16   end while 17   ReturnToLevel(0) 18   End all nested records 19   return record 20 end procedure 21  22 MoveToLevel(int newLevel, FieldReader nextReader): 23      End nested records up to the level of the lowest common ancestor 24          of lastReader  and nextReader. 25      Start nested records from the level of the lowest common ancestor 26          up to newLevel. 27     Set lastReader to the one at newLevel. 28 end procedure 29  30 ReturnToLevel(int newLevel) { 31     End nested records up to newLevel. 32     Set lastReader to the one at newLevel. 33 end procedure \fFigure 19 shows the algorithm used for evaluating select-project-\n",
      "aggregate queries in Dremel. The algorithm addresses a general\n",
      "case when a query may reference repeated ﬁelds; a simpler opti-\n",
      "mized version is used for ﬂat-relational queries, i.e., those refer-\n",
      "encing only required and optional ﬁelds. The algorithm has two\n",
      "implicit inputs: a set of FieldReaders, one for each ﬁeld appearing\n",
      "in the query, and a set of scalar expressions, including aggregate\n",
      "expressions, present in the query. The repetition level of a scalar\n",
      "expression (used in Line 8) is determined as the maximum repeti-\n",
      "tion level of the ﬁelds used in that expression.\n",
      "\n",
      "In essence, the algorithm advances the readers in lockstep to the\n",
      "next set of values, and, if the selection conditions are met, emits\n",
      "the projected values. Selection and projection are controlled by\n",
      "two variables, fetchLevel and selectLevel. During execution, only\n",
      "\n",
      "Figure 18: Algorithm to construct a record assembly automaton\n",
      "\n",
      "C. FSM CONSTRUCTION ALGORITHM\n",
      "Figure 18 shows an algorithm for constructing a ﬁnite-state ma-\n",
      "chine that performs record assembly. The algorithm takes as input\n",
      "the ﬁelds that should be populated in the records, in the order in\n",
      "which they appear in the schema. The algorithm uses a concept of\n",
      "a ‘common repetition level’ of two ﬁelds, which is the repetition\n",
      "level of their lowest common ancestor. For example, the common\n",
      "repetition level of Links.Backward and Links.Forward equals 1. The\n",
      "second concept is that of a ‘barrier’, which is the next ﬁeld in the\n",
      "sequence after the current one. The intuition is that we try to pro-\n",
      "cess each ﬁeld one by one until the barrier is hit and requires a jump\n",
      "to a previously seen ﬁeld.\n",
      "\n",
      "The algorithm consists of three steps. In Step 1 (Lines 6-10),\n",
      "we go through the common repetition levels backwards. These are\n",
      "guaranteed to be non-increasing. For each repetition level we en-\n",
      "counter, we pick the left-most ﬁeld in the sequence—that is the one\n",
      "we need to transition to when that repetition level is returned by a\n",
      "FieldReader. In Step 2, we ﬁll the gaps (Lines 11-14). The gaps\n",
      "arise because not all repetition levels are present in the common\n",
      "repetition levels computed at Line 8. In Step 3 (Lines 15-17), we\n",
      "set transitions for all levels that are equal to or below the barrier\n",
      "level to jump to the barrier ﬁeld. If a FieldReader produces such\n",
      "a level, we need to continue constructing the nested record and do\n",
      "not need to bounce off the barrier.\n",
      "\n",
      "D. SELECT-PROJECT-AGGREGATE\n",
      "EVALUATION ALGORITHM\n",
      "\n",
      "Figure 19: Algorithm for evaluating select-project-aggregate\n",
      "queries over columnar input, bypassing record assembly\n",
      "\n",
      "readers whose next repetition level is no less than fetchLevel are\n",
      "advanced (see Fetch method at Line 19). In a similar vein, only ex-\n",
      "pressions whose current repetition level is no less than selectLevel\n",
      "are emitted (Lines 7-10). The algorithm ensures that expressions\n",
      "at a higher-level of nesting, i.e., those having a smaller repetition\n",
      "level, get evaluated and emitted only once for each deeper nested\n",
      "expression.\n",
      "\n",
      " 1 procedure ConstructFSM(Field[] fields):  2 for each field in fields:  3   maxLevel = maximal repetition level of field   4   barrier = next field after field or final FSM state otherwise  5   barrierLevel = common repetition level of field and barrier  6   for each preField before field whose   7                  repetition level is larger than barrierLevel:  8     backLevel = common repetition level of preField and field  9     Set transition (field, backLevel) -> preField 10   end for 11   for each level in [barrierLevel+1..maxLevel] 12       that lacks transition from field: 13           Copy transition's destination from that of level-1 14   end for 15   for each level in [0..barrierLevel]:   16            Set transition (field, level) -> barrier 17   end for 18 end for  19 end procedure  1 procedure Scan():  2   fetchLevel = 0   3   selectLevel = 0  4   while stopping conditions are not met:  5     Fetch()  6     if WHERE clause evaluates to true:  7       for each expression in SELECT clause:  8         if (repetition level of expression) >= selectLevel:  9           Emit value of expression 10         end if   11       end for 12       selectLevel = fetchLevel 13     else 14       selectLevel = min(selectLevel, fetchLevel) 15     end if   16   end while 17 end procedure 18 19 procedure Fetch(): 20   nextLevel = 0  21   for each reader in field reader set: 22     if (next repetition level of reader) >=  fetchLevel: 23       Advance reader to the next value 24     endif   25     nextLevel = max(nextLevel, next repetition level of reader)  26   end for 27   fetchLevel = nextLevel  28 end procedure \f\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
